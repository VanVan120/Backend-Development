{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93212d1e",
   "metadata": {},
   "source": [
    "# Model A: Master Training Notebook (OSCC Analysis)\n",
    "**Role:** Senior Computer Vision Engineer & MLOps Specialist\n",
    "**Objective:** Train a Multi-Task Learning (MTL) model for OSCC WSI Analysis.\n",
    "**Status:** Pre-data phase (Using Dummy Data for pipeline verification).\n",
    "\n",
    "## Tasks\n",
    "1.  **TVNT:** Tumour vs Non-Tumour (Binary Classification)\n",
    "2.  **DOI:** Depth of Invasion (Segmentation -> Depth Calc)\n",
    "3.  **POI:** Pattern of Invasion (5-Class Classification)\n",
    "4.  **TB:** Tumour Budding (Count Regression)\n",
    "5.  **PNI:** Perineural Invasion (Binary Classification)\n",
    "6.  **MI:** Mitotic Index (Count Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef8f445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# 1. Imports & Setup\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd  # Added pandas for CSV handling\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25bb5f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Architecture Defined.\n"
     ]
    }
   ],
   "source": [
    "# 2. Model Definition (DenseNet169 Backbone)\n",
    "\n",
    "class UpsampleBlock(nn.Module):\n",
    "    \"\"\"Helper block for the Segmentation Decoder.\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.upsample(self.conv(x))\n",
    "\n",
    "class OSCCMultiTaskModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Backbone: DenseNet169\n",
    "        self.backbone = models.densenet169(pretrained=True)\n",
    "        num_ftrs = self.backbone.classifier.in_features\n",
    "        \n",
    "        # Remove original classifier\n",
    "        self.backbone.classifier = nn.Identity()\n",
    "        \n",
    "        # --- HEADS ---\n",
    "        \n",
    "        # 1. TVNT (Binary: Tumour vs Non-Tumour)\n",
    "        self.head_tvnt = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 2) \n",
    "        )\n",
    "        \n",
    "        # 2. POI (5 Classes: Pattern of Invasion)\n",
    "        self.head_poi = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 5)\n",
    "        )\n",
    "        \n",
    "        # 3. PNI (Binary: Present vs Absent)\n",
    "        self.head_pni = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 2)\n",
    "        )\n",
    "        \n",
    "        # 4. TB (Regression: Count of Tumour Buds)\n",
    "        self.head_tb = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1) # Output raw count\n",
    "        )\n",
    "        \n",
    "        # 5. MI (Regression: Count of Mitotic Figures)\n",
    "        self.head_mi = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1) # Output raw count\n",
    "        )\n",
    "        \n",
    "        # 6. DOI (Segmentation: Depth of Invasion Mask)\n",
    "        # Note: DenseNet169 features shape depends on input. \n",
    "        # We will use a simplified decoder for this demo.\n",
    "        self.decoder = nn.Sequential(\n",
    "            UpsampleBlock(num_ftrs, 512), # /32 -> /16\n",
    "            UpsampleBlock(512, 256),      # /16 -> /8\n",
    "            UpsampleBlock(256, 128),      # /8 -> /4\n",
    "            UpsampleBlock(128, 64),       # /4 -> /2\n",
    "            UpsampleBlock(64, 32),        # /2 -> /1\n",
    "            nn.Conv2d(32, 1, kernel_size=1) # Output: 1 channel mask\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Extract features\n",
    "        # DenseNet features are (B, 1664, H/32, W/32)\n",
    "        features = self.backbone.features(x)\n",
    "        \n",
    "        # Global Average Pooling for Classification/Regression Heads\n",
    "        pooled = F.relu(features, inplace=True)\n",
    "        pooled = F.adaptive_avg_pool2d(pooled, (1, 1))\n",
    "        pooled = torch.flatten(pooled, 1)\n",
    "        \n",
    "        # Task Outputs\n",
    "        out_tvnt = self.head_tvnt(pooled)\n",
    "        out_poi = self.head_poi(pooled)\n",
    "        out_pni = self.head_pni(pooled)\n",
    "        out_tb = self.head_tb(pooled)\n",
    "        out_mi = self.head_mi(pooled)\n",
    "        \n",
    "        # Segmentation Output\n",
    "        out_doi = self.decoder(features)\n",
    "        \n",
    "        return {\n",
    "            'tvnt': out_tvnt,\n",
    "            'poi': out_poi,\n",
    "            'pni': out_pni,\n",
    "            'tb': out_tb,\n",
    "            'mi': out_mi,\n",
    "            'doi': out_doi\n",
    "        }\n",
    "\n",
    "print(\"Model Architecture Defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5ad81ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOI Calculation Function Defined.\n"
     ]
    }
   ],
   "source": [
    "# 3. Logic & Metrics (DOI Calculation)\n",
    "\n",
    "def calculate_doi_from_mask(mask_tensor, pixel_spacing_mm=0.00025):\n",
    "    \"\"\"\n",
    "    Calculates Depth of Invasion (DOI) from a binary segmentation mask.\n",
    "    \n",
    "    Args:\n",
    "        mask_tensor (torch.Tensor): Shape (1, H, W), values 0 or 1.\n",
    "        pixel_spacing_mm (float): Physical size of one pixel in mm.\n",
    "        \n",
    "    Returns:\n",
    "        float: Depth in mm.\n",
    "    \"\"\"\n",
    "    mask = mask_tensor.squeeze().cpu().numpy().astype(np.uint8)\n",
    "    \n",
    "    if np.sum(mask) == 0:\n",
    "        return 0.0\n",
    "        \n",
    "    # Find all tumour pixels\n",
    "    y_indices, x_indices = np.where(mask > 0)\n",
    "    \n",
    "    if len(y_indices) == 0:\n",
    "        return 0.0\n",
    "        \n",
    "    # Heuristic: DOI is distance from the \"top-most\" tumour pixel (superficial)\n",
    "    # to the \"bottom-most\" tumour pixel (deepest).\n",
    "    # In a real scenario, we would need a reference 'mucosal line'.\n",
    "    # Here we assume the image is oriented such that 'up' is superficial.\n",
    "    \n",
    "    min_y = np.min(y_indices)\n",
    "    max_y = np.max(y_indices)\n",
    "    \n",
    "    pixel_depth = max_y - min_y\n",
    "    doi_mm = pixel_depth * pixel_spacing_mm\n",
    "    \n",
    "    return doi_mm\n",
    "\n",
    "print(\"DOI Calculation Function Defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185b0a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Dataset & DataLoader Created.\n"
     ]
    }
   ],
   "source": [
    "# 4. Real Dataset Loader\n",
    "\n",
    "class OSCCRealDataset(Dataset):\n",
    "    def __init__(self, img_dir, mask_dir=None, csv_file=None, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Load Labels\n",
    "        if csv_file and os.path.exists(csv_file):\n",
    "            self.df = pd.read_csv(csv_file)\n",
    "            print(f\"Loaded {len(self.df)} samples from {csv_file}\")\n",
    "        else:\n",
    "            # Fallback: List all images, set labels to default/dummy\n",
    "            self.image_files = [f for f in os.listdir(img_dir) if f.endswith(('.jpg', '.png'))] if os.path.exists(img_dir) else []\n",
    "            self.df = pd.DataFrame({'filename': self.image_files})\n",
    "            # Add default columns if missing\n",
    "            for col in ['tvnt', 'poi', 'pni', 'tb', 'mi']:\n",
    "                self.df[col] = 0\n",
    "            print(f\"No CSV found. Found {len(self.df)} images in '{img_dir}'. Using placeholder labels (0).\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_name = row['filename']\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        \n",
    "        # 1. Load Image\n",
    "        try:\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "        except:\n",
    "            # Fallback for missing file (return black image)\n",
    "            image = Image.new('RGB', (224, 224))\n",
    "            \n",
    "        # 2. Load Mask (if exists)\n",
    "        mask = np.zeros((224, 224), dtype=np.float32)\n",
    "        if self.mask_dir:\n",
    "            # Assume mask has same name but png\n",
    "            mask_name = os.path.splitext(img_name)[0] + \".png\"\n",
    "            mask_path = os.path.join(self.mask_dir, mask_name)\n",
    "            if os.path.exists(mask_path):\n",
    "                m = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "                if m is not None:\n",
    "                    m = cv2.resize(m, (224, 224), interpolation=cv2.INTER_NEAREST)\n",
    "                    mask = m / 255.0 # Normalize to 0-1\n",
    "        \n",
    "        # 3. Load Labels\n",
    "        label_tvnt = int(row.get('tvnt', 0))\n",
    "        label_poi = int(row.get('poi', 0))\n",
    "        label_pni = int(row.get('pni', 0))\n",
    "        label_tb = float(row.get('tb', 0.0))\n",
    "        label_mi = float(row.get('mi', 0.0))\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        mask = torch.tensor(mask).unsqueeze(0).float()\n",
    "        \n",
    "        return {\n",
    "            'image': image,\n",
    "            'tvnt': torch.tensor(label_tvnt, dtype=torch.long),\n",
    "            'poi': torch.tensor(label_poi, dtype=torch.long),\n",
    "            'pni': torch.tensor(label_pni, dtype=torch.long),\n",
    "            'tb': torch.tensor(label_tb, dtype=torch.float),\n",
    "            'mi': torch.tensor(label_mi, dtype=torch.float),\n",
    "            'doi': mask\n",
    "        }\n",
    "\n",
    "# Configuration\n",
    "DATASET_ROOT = \"dataset\"\n",
    "IMG_DIR = os.path.join(DATASET_ROOT, \"images\")\n",
    "MASK_DIR = os.path.join(DATASET_ROOT, \"masks\")\n",
    "CSV_FILE = os.path.join(DATASET_ROOT, \"labels.csv\")\n",
    "\n",
    "# Create directories if they don't exist (Helper for user)\n",
    "os.makedirs(IMG_DIR, exist_ok=True)\n",
    "os.makedirs(MASK_DIR, exist_ok=True)\n",
    "\n",
    "# Transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Initialize Dataset\n",
    "train_dataset = OSCCRealDataset(IMG_DIR, MASK_DIR, CSV_FILE, transform=train_transform)\n",
    "\n",
    "if len(train_dataset) > 0:\n",
    "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "    print(\"‚úÖ Real Dataset Loaded Successfully.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Dataset folder is empty. Please add images to 'dataset/images' and a 'labels.csv'.\")\n",
    "    # Create dummy loader to prevent crash if user runs without data\n",
    "    dummy_ds = OSCCRealDataset(IMG_DIR, csv_file=None, transform=train_transform)\n",
    "    dummy_ds.df = pd.DataFrame({'filename': ['dummy.jpg'], 'tvnt':[0], 'poi':[0], 'pni':[0], 'tb':[0], 'mi':[0]})\n",
    "    train_loader = DataLoader(dummy_ds, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f08ced",
   "metadata": {},
   "source": [
    "## 4. Dataset Configuration (Real Data)\n",
    "**Instructions for User:**\n",
    "To train on real data, organize your files as follows:\n",
    "1.  **Images:** Put your `.jpg` patches in `dataset/images/`.\n",
    "2.  **Masks (Optional):** Put segmentation masks in `dataset/masks/` (same filename as image, but `.png`).\n",
    "3.  **Labels:** Create a `dataset/labels.csv` with the following columns:\n",
    "    *   `filename`: e.g., \"slide1_patch_0_0.jpg\"\n",
    "    *   `tvnt`: 0 (Normal) or 1 (Tumour)\n",
    "    *   `poi`: 0-4 (Pattern of Invasion type)\n",
    "    *   `pni`: 0 (No) or 1 (Yes)\n",
    "    *   `tb`: Integer count of tumour buds\n",
    "    *   `mi`: Integer count of mitotic figures\n",
    "\n",
    "*If no data is found, the code will warn you but won't crash.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc8ef5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet169_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet169_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Loop...\n",
      "Epoch [1/2], Loss: 91.3662\n",
      "Epoch [1/2], Loss: 91.3662\n",
      "Epoch [2/2], Loss: 86.5585\n",
      "Training Complete.\n",
      "Epoch [2/2], Loss: 86.5585\n",
      "Training Complete.\n"
     ]
    }
   ],
   "source": [
    "# 5. Training Loop\n",
    "\n",
    "model = OSCCMultiTaskModel().to(DEVICE)\n",
    "\n",
    "# Check if pretrained model exists and load it (Resume Training)\n",
    "if os.path.exists(\"model_a.pth\"):\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(\"model_a.pth\", map_location=DEVICE))\n",
    "        print(\"‚úÖ Loaded existing model weights from model_a.pth. Resuming training...\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not load model weights: {e}. Starting from scratch.\")\n",
    "else:\n",
    "    print(\"üÜï No existing model found. Starting training from scratch.\")\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Loss Functions\n",
    "criterion_cls = nn.CrossEntropyLoss() # For TVNT, POI, PNI\n",
    "criterion_reg = nn.MSELoss()          # For TB, MI\n",
    "criterion_seg = nn.BCEWithLogitsLoss() # For DOI Mask\n",
    "\n",
    "NUM_EPOCHS = 2\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        images = batch['image'].to(DEVICE)\n",
    "        \n",
    "        # Move targets to device\n",
    "        target_tvnt = batch['tvnt'].to(DEVICE)\n",
    "        target_poi = batch['poi'].to(DEVICE)\n",
    "        target_pni = batch['pni'].to(DEVICE)\n",
    "        target_tb = batch['tb'].to(DEVICE).unsqueeze(1) # (B, 1)\n",
    "        target_mi = batch['mi'].to(DEVICE).unsqueeze(1) # (B, 1)\n",
    "        target_doi = batch['doi'].to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward Pass\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Calculate Losses\n",
    "        loss_tvnt = criterion_cls(outputs['tvnt'], target_tvnt)\n",
    "        loss_poi = criterion_cls(outputs['poi'], target_poi)\n",
    "        loss_pni = criterion_cls(outputs['pni'], target_pni)\n",
    "        loss_tb = criterion_reg(outputs['tb'], target_tb)\n",
    "        loss_mi = criterion_reg(outputs['mi'], target_mi)\n",
    "        \n",
    "        # Resize mask output to match target if needed (due to pooling/upsampling)\n",
    "        # Our decoder outputs 224x224 so it should match\n",
    "        loss_doi = criterion_seg(outputs['doi'], target_doi)\n",
    "        \n",
    "        # Total Loss (Weighted Sum - can tune weights later)\n",
    "        total_loss = (loss_tvnt + loss_poi + loss_pni + \n",
    "                      0.5 * loss_tb + 0.5 * loss_mi + \n",
    "                      1.0 * loss_doi)\n",
    "        \n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += total_loss.item()\n",
    "        \n",
    "    print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "print(\"Training Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d0416cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to model_a.pth\n"
     ]
    }
   ],
   "source": [
    "# 6. Export Model\n",
    "save_path = \"model_a.pth\"\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(f\"Model saved to {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
